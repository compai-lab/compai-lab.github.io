<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lina Felsner | Computational Imaging and AI in Medicine</title>
    <link>https://compai-lab.io/author/lina-felsner/</link>
      <atom:link href="https://compai-lab.io/author/lina-felsner/index.xml" rel="self" type="application/rss+xml" />
    <description>Lina Felsner</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 07 Nov 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://compai-lab.io/author/lina-felsner/avatar_hu60e932604a75cc0995bfb2f4902df59a_1322838_270x270_fill_q75_lanczos_center.jpg</url>
      <title>Lina Felsner</title>
      <link>https://compai-lab.io/author/lina-felsner/</link>
    </image>
    
    <item>
      <title>Multiparametric (TI-TE) MRI sequence adaptation and implicit neural representation (INR)-based reconstruction</title>
      <link>https://compai-lab.io/vacancies/msc_niessen_reconstruction_26/</link>
      <pubDate>Fri, 07 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_niessen_reconstruction_26/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Multiparametric MRI sequences allow for the acquisition of images with varying tissue contrast within a single scan. The resulting multiparametric images can be used to extract quantitative information on tissue microstructure. To make such multiparametric sequences feasible for clinical routine, the usually very long scan times need to be shortened e.g. through undersampling in k-space. However, this comes with challenges for the reconstruction. In general, advanced reconstruction techniques such as compressed sensing or deep learning based approaches (1) can enable the acquisition of high-quality images despite the acceleration. For multiparametric MRI sequences very high accelerations can be achieved by leveraging redundant anatomical information e.g. through joint reconstruction with an implicit neural representation (INR) network (2).&lt;/p&gt;
&lt;p&gt;This project aims to extend an MPnRAGE (3) (multiple inversion times, TI) acquisition and reconstruction framework by adding an echo time (TE) dimension. The first part of the project will involve modifying the existing MPnRAGE sequence, including iterative improvements on the scanner. The second part of the project will focus on adapting the INR-based reconstruction for the multiparametric (TI-TE) data.&lt;/p&gt;
&lt;p&gt;The student will benefit from:
• Guidance from both MRI and AI experts in a collaborative, interdisciplinary research
setting.
• Hands on experience with the MRI scanner and coding.
• Opportunity to contribute to ongoing research and potential publication in medical
imaging journals or conferences.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-object and multi-modal image segmentation in dental MR using limited data</title>
      <link>https://compai-lab.io/vacancies/msc_lina_dental/</link>
      <pubDate>Wed, 04 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_lina_dental/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Deep learning methods have revolutionized the field of medical imaging, in particular image segmentation. Supervised methods, often based on the popular U-Net architecture, show state-of-the-art results in many medical applications. But a large annotated database for training is not always available. The objective of this project is to explore and develop methods for learning segmentations using limited data, e.g., using transfer [1], self-supervised [2,3] or meta learning [4–6]. This project is a collaboration between the Department of Diagnostic and Interventional Neuroradiology (TUM), the Department of Periodontology (LMU) and the Chair of the Artificial Intelligence in Medicine (TUM).&lt;/p&gt;
&lt;p&gt;The clinical application is the identification of periodontal lesions in magnetic resonance (MR) and computed tomography (CT) images. The study aims at detecting intraosseous pathologies automatically. Periodontitis (chronic or acute alterations of the periodontium) is among the globally widest spread diseases, and interacts with cardiovascular and metabolic disorders. The diagnosis and monitoring of periodontitis is mainly based on imaging modalities exhibiting ionizing radiation: X-ray (panoramic radiography) and cone-beam CT. Recent studies report the successful use of MR imaging in the application of periodontitis diagnosis [7]. Two MRI sequences were developed: a T1-weighted sequence to visualise osseous tissue, and a T2-weighted sequence to visualise the periodontal lesion. To enable automatic diagnosis and monitoring of the disease, accurate segmentations of the bone and periodontal lesion are of utmost importance. A prior collaborative effort between the previously mentioned departments has already resulted in the development of an AI algorithm capable of differentiating between bone and nerve tissue in the mandibular bone. The subsequent objective is to automatically detect periodontal lesions within the bone. [8]&lt;/p&gt;
&lt;p&gt;The prospective student will explore existing deep-learning-based segmentation methods for training with limited data, to segment periodontal lesions in MR sequences.&lt;/p&gt;
&lt;p&gt;Requirements:&lt;/p&gt;
&lt;p&gt;• Prior experience and good understanding in machine learning and statistics.
• Very good programming skills in Python (and PyTorch).
• Interest in medical imaging.&lt;/p&gt;
&lt;p&gt;References
[1]  Cheplygina, V. ”Cats or CAT scans: Transfer learning from natural or medical image source data sets?.” Current Opinion in Biomedical Engineering 9: 21-27, 2019.
[2]  Chen, L., et al. Self-supervised learning for medical image analysis using image context restoration. Medical image analysis, 58, 101539, 2019.
[3]  Taleb, A., et al. ”Multimodal self-supervised learning for medical image analysis.” International Conference on Information Processing in Medical Imaging. Springer, Cham, 2021.
[4]  Li, X., et al. ”A concise review of recent few-shot meta-learning methods.” Neuro- computing 456: 463-468, 2021.
[5]  Yang, B., et al. ”Prototype mixture models for few-shot semantic segmentation.” European Conference on Computer Vision. Springer, Cham, 2020.
[6]  Tian, P., et al. ”Differentiable meta-learning model for few-shot semantic segmen- tation.” Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 07. 2020.
[7]  Probst, M., et al. ”Magnetic resonance imaging as a diagnostic tool for periodontal disease: A prospective study with correlation to standard clinical findings - Is there added value?” Journal of Clinical Periodontology, 2021.
[8] Xingyu, Z., (2024) “Multi-object and Multi-modal Image Segmentation in Dental MRI”. School of Computation, Information and Technology, Technical University of Munich, Munich.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning for Inverse Problems in Medical Imaging​ (IN2107)</title>
      <link>https://compai-lab.io/teaching/inv_seminar/</link>
      <pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/teaching/inv_seminar/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://compai-lab.io/images/InvPr_seminar.jpg&#34; alt=&#34;Teaser&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;More information will be provided during an introduction meeting scheduled at 10/02/2025 at 10am via Zoom:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://tum-conf.zoom-x.de/j/63305971488?pwd=VdbDeahxywbJSmpBuDlvNxjNW1BLbj.1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tum-conf.zoom-x.de/j/63305971488?pwd=VdbDeahxywbJSmpBuDlvNxjNW1BLbj.1&lt;/a&gt;, Meeting ID: 633 0597 1488 Passcode: 684506&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In medical imaging, the reconstruction of high-quality images from incomplete or corrupted data often involves solving inverse problems. Deep learning has emerged as a powerful tool for addressing these challenges, offering approaches to improve image reconstruction quality, enhance computational efficiency, and tackle complex non-linearities.
This seminar explores the concepts of deep learning for inverse problems, focusing on their applications in medical imaging. Selected materials from recent methodological advances will be covered as well as key challenges and opportunities in leveraging deep learning for clinical applications.&lt;/p&gt;
&lt;p&gt;Key topics to be covered include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to inverse problems in medical imaging&lt;/li&gt;
&lt;li&gt;Deep learning approaches for solving inverse problems&lt;/li&gt;
&lt;li&gt;Applications in various medical imaging modalities (e.g., MRI, CT, PET)&lt;/li&gt;
&lt;li&gt;Comparison of traditional and deep learning-based methods&lt;/li&gt;
&lt;li&gt;Emerging trends and clinical implications&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Please register at: &lt;a href=&#34;https://matching.in.tum.de/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://matching.in.tum.de/&lt;/a&gt; or write an e-mail to &lt;a href=&#34;mailto:hannah.eichhorn@tum.de&#34;&gt;hannah.eichhorn@tum.de&lt;/a&gt;, &lt;a href=&#34;mailto:lina.felsner@tum.de&#34;&gt;lina.felsner@tum.de&lt;/a&gt; or &lt;a href=&#34;mailto:s.kafali@tum.de&#34;&gt;s.kafali@tum.de&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Check the intro slides here:&lt;/p&gt;
&lt;object data=&#34;/files/InvPr_seminar.pdf&#34; type=&#34;application/pdf&#34; width=&#34;100%&#34; height=&#34;400&#34;&gt; 
&lt;/object&gt;
</description>
    </item>
    
    <item>
      <title>Eleven papers accepted at MICCAI Workshops 2024</title>
      <link>https://compai-lab.io/post/miccai_workshops_24/</link>
      <pubDate>Fri, 05 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/post/miccai_workshops_24/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Selective Test-Time Adaptation using Neural Implicit Representations for Unsupervised Anomaly Detection [Best Paper Award]&lt;/strong&gt;&lt;br&gt;
Sameer Ambekar, Julia Schnabel, and Cosmin I. Bercea. &lt;br&gt;
&lt;a href=&#34;https://arxiv.org/abs/2410.03306&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2410.03306&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MedEdit: Counterfactual Diffusion-based Image Editing on Brain MRI&lt;/strong&gt;&lt;br&gt;
Malek Ben Alaya, Daniel M. Lang, Benedikt Wiestler, Julia A. Schnabel, and Cosmin I. Bercea&lt;br&gt;
(&lt;a href=&#34;https://arxiv.org/pdf/2407.15270&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/2407.15270&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Unsupervised Analysis of Alzheimer’s Disease Signatures using 3D Deformable Autoencoders&lt;/strong&gt;&lt;br&gt;
Mehmet Yigit Avci, Emily Chan, Veronika Zimmer, Daniel Rueckert, Benedikt Wiestler, Julia A. Schnabel, and Cosmin I. Bercea&lt;br&gt;
(&lt;a href=&#34;https://arxiv.org/pdf/2407.03863&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/2407.03863&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;On Differentially Private 3D Medical Image Synthesis with Controllable Latent Diffusion Models&lt;/strong&gt;&lt;br&gt;
Deniz Daum; Richard Osuala; Anneliese Riess; Georgios Kaissis; Julia A. Schnabel; Maxime Di Folco&lt;br&gt;
(&lt;a href=&#34;https://arxiv.org/abs/2407.16405&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2407.16405&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph Neural Networks: A suitable alternative to MLPs in latent 3D medical image classification?&lt;/strong&gt;&lt;br&gt;
Johannes Kiechle, Daniel M. Lang, Stefan M. Fischer, Lina Felsner, Jan C. Peeken, Julia A. Schnabel&lt;br&gt;
(&lt;a href=&#34;http://arxiv.org/abs/2407.17219&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://arxiv.org/abs/2407.17219&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;General Vision Encoder Features as Guidance in Medical Image Registration&lt;/strong&gt;&lt;br&gt;
Fryderyk Kögl, Anna Reithmeir, Vasiliki Sideri-Lampretsa, Ines Machado, Rickmer Braren, Daniel Rückert, Julia A Schnabel, Veronika A Zimmer&lt;br&gt;
(&lt;a href=&#34;https://arxiv.org/abs/2407.13311&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2407.13311&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Language Models Meet Anomaly Detection for Better Interpretability and Generalizability&lt;/strong&gt;&lt;br&gt;
Jun Li, Su Hwan Kim, Philip Müller, Lina Felsner, Daniel Rueckert, Benedikt Wiestler, Julia A.Schnabel, and Cosmin I. Bercea&lt;br&gt;
(&lt;a href=&#34;https://arxiv.org/pdf/2404.07622v2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/2404.07622v2&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;A Self-Supervised Image Registration Approach for Measuring Local Response Patterns in Metastatic Ovarian Cancer&lt;/strong&gt;&lt;br&gt;
Inês P. Machado, Anna Reithmeir, Fryderyk Kogl, Leonardo Rundo, Gabriel Funingana, Marika Reinius, Gift Mungmeeprued, Zeyu Gao, Cathal McCague, Eric Kerfoot, Ramona Woitek, Evis Sala, Yangming Ou, James Brenton, Julia Schnabel, Mireia Crispin&lt;br&gt;
(&lt;a href=&#34;https://arxiv.org/abs/2407.17114&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2407.17114&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Diffusion Models for Unsupervised Anomaly Detection in Fetal Brain Ultrasound&lt;/strong&gt;&lt;br&gt;
Hanna Mykula, Lisa Gasser, Silvia Lobmaier, Julia A. Schnabel, Veronika Zimmer, and Cosmin I. Bercea&lt;br&gt;
(&lt;a href=&#34;https://arxiv.org/pdf/2407.15119&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/2407.15119&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data&lt;/strong&gt;&lt;br&gt;
Richard Osuala, Daniel M. Lang, Anneliese Riess, Georgios Kaissis, Zuzanna Szafranowska, Grzegorz Skorupko, Oliver Diaz, Julia A. Schnabel, Karim Lekadir&lt;br&gt;
(&lt;a href=&#34;https://arxiv.org/abs/2407.12669&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2407.12669&lt;/a&gt;)&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Complex-valued Federated Learning with Differential Privacy and MRI Applications&lt;/strong&gt;&lt;br&gt;
Anneliese Riess, Alexander Ziller, Stefan Kolek, Daniel Rueckert, Julia Schnabel, Georgios Kaissis &lt;br&gt;
([link will be available soon])&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
