<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Open Positions | Computational Imaging and AI in Medicine</title>
    <link>https://compai-lab.io/vacancies/</link>
      <atom:link href="https://compai-lab.io/vacancies/index.xml" rel="self" type="application/rss+xml" />
    <description>Open Positions</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 01 Sep 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://compai-lab.io/media/icon_hu790efcb2e4090d1e7a0ffec0a0776e8f_331139_512x512_fill_lanczos_center_3.png</url>
      <title>Open Positions</title>
      <link>https://compai-lab.io/vacancies/</link>
    </image>
    
    <item>
      <title>Med-VLM - Prompt Adaptation of Vision-Language Models to Medical Domains</title>
      <link>https://compai-lab.io/vacancies/msc_med-vlm_sameer/</link>
      <pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_med-vlm_sameer/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Medical imaging faces persistent domain shifts across scanners, protocols, pathologies, and populations. Recent vision-language models, such as CLIP (Contrastive Language-Image Pre-training), learns joint representations from image-text pairs, enabling zero-shot transfer to new visual concepts through natural language descriptions. Although the recent works demonstrate that CLIP based models offer strong zero-shot transfer, their performance degrades on unseen medical data.&lt;/p&gt;
&lt;p&gt;Recent adaptation techniques aim to mitigate this by proposing prompt-based, parameter-efficient, and feature-level strategies. Complementing this, text-only prompt learning optimizes prompts in the text space using LLM-derived biomedical descriptions or ontology-based prototypes, improving transfer to unseen data. This Master&amp;rsquo;s thesis proposes adapting CLIP-based models to unseen medical data through techniques including prompt learning and CLIP&amp;rsquo;s consistent contrastive alignment, emphasizing practical clinical feasibility.&lt;/p&gt;
&lt;p&gt;This Master thesis aims to analyze and propose: (i) an adaptation framework that leverages medical concepts into prompts to improve robustness on unseen data, (ii) prompt-based adaptation procedures for non-independent and identically distributed (non-i.i.d) shifts through lightweight mechanisms, (iii) a comprehensive evaluation on multi-source medical benchmarks. Expected outcomes include, but are not limited to: a vision and language-guided framework for medical imaging that improves generalization across multiple scanners and diverse population data, a lightweight test-time adaptation method with biomedical prompts, and analysis on medical benchmarks with ablations under realistic scenarios. This Master&amp;rsquo;s thesis aspires to publish results in a relevant academic venue.&lt;/p&gt;
&lt;p&gt;The start date ideally is Sept/Oct 2025. The thesis is offered by the Chair for Computational Imaging and AI in Medicine (Prof. Dr. Julia Schnabel) and supervised by Sameer Ambekar and Dr. Daniel Lang. If interested, please email your transcripts and a short motivation to &lt;a href=&#34;mailto:sameer.ambekar@tum.de&#34;&gt;sameer.ambekar@tum.de&lt;/a&gt; and
&lt;a href=&#34;mailto:lang@helmholtz-munich.de&#34;&gt;lang@helmholtz-munich.de&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning from Many - Domain Generalization for Medical Imaging</title>
      <link>https://compai-lab.io/vacancies/msc_ambekar_domain_shift_25/</link>
      <pubDate>Wed, 04 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_ambekar_domain_shift_25/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Deep learning achieves good performance when training and test data share similar distribution characteristics. However, for real-world scenarios—including medical imaging and natural scenes—significant domain shifts caused by diverse data characteristics and scanner settings often prevent models from generalizing to unseen domains. To address this at the model level, domain adaptation and domain generalization have emerged as potential solutions. Domain adaptation relies on access to target data to learn target representations, while domain generalization aims to learn invariant representations and obtain robust models using only source domains. Recently, a new paradigm called test-time adaptation further optimizes the model during online inference on the target domain to boost performance.&lt;/p&gt;
&lt;p&gt;Despite these advancements, existing adaptation methods struggle with unique challenges in the target domain. These include class imbalance, category shifts within domains, reliance on unsupervised surrogate objectives, and non-i.i.d. assumptions that lead to error accumulation. Moreover, the scarcity of large annotated datasets limits the ability of models to learn meaningful representations for transfer. Recent studies also show that existing methods do not consistently improve performance in multi-source, real-world scenarios such as medical imaging.&lt;/p&gt;
&lt;p&gt;This master’s thesis proposes new domain generalization and adaptation techniques to address these challenges. First, it will train models on multi-source data drawn from diverse distributions—different scanners, pathologies, and demographics. Next, it will explore existing domain generalization algorithms, analyzing the role of entropy minimization for optimizing model performance and the impact of feature alignment. Finally, it seeks to introduce novel contributions grounded in fundamental deep learning principles, with the goal of enhancing the adaptability and robustness of models across varied environments. The research outcomes are intended for publication in a relevant academic venue.&lt;/p&gt;
&lt;p&gt;The start date ideally is June 2025. The thesis is offered by the Chair for Computational Imaging and AI in Medicine (Prof. Dr. Julia Schnabel) and supervised by Sameer Ambekar and Dr. Daniel Lang. If interested, please send your transcripts and a short motivation to &lt;a href=&#34;mailto:sameer.ambekar@tum.de&#34;&gt;sameer.ambekar@tum.de&lt;/a&gt; and
&lt;a href=&#34;mailto:lang@helmholtz-munich.de&#34;&gt;lang@helmholtz-munich.de&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-object and multi-modal image segmentation in dental MR using limited data</title>
      <link>https://compai-lab.io/vacancies/msc_lina_dental/</link>
      <pubDate>Wed, 04 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_lina_dental/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Deep learning methods have revolutionized the field of medical imaging, in particular image segmentation. Supervised methods, often based on the popular U-Net architecture, show state-of-the-art results in many medical applications. But a large annotated database for training is not always available. The objective of this project is to explore and develop methods for learning segmentations using limited data, e.g., using transfer [1], self-supervised [2,3] or meta learning [4–6]. This project is a collaboration between the Department of Diagnostic and Interventional Neuroradiology (TUM), the Department of Periodontology (LMU) and the Chair of the Artificial Intelligence in Medicine (TUM).&lt;/p&gt;
&lt;p&gt;The clinical application is the identification of periodontal lesions in magnetic resonance (MR) and computed tomography (CT) images. The study aims at detecting intraosseous pathologies automatically. Periodontitis (chronic or acute alterations of the periodontium) is among the globally widest spread diseases, and interacts with cardiovascular and metabolic disorders. The diagnosis and monitoring of periodontitis is mainly based on imaging modalities exhibiting ionizing radiation: X-ray (panoramic radiography) and cone-beam CT. Recent studies report the successful use of MR imaging in the application of periodontitis diagnosis [7]. Two MRI sequences were developed: a T1-weighted sequence to visualise osseous tissue, and a T2-weighted sequence to visualise the periodontal lesion. To enable automatic diagnosis and monitoring of the disease, accurate segmentations of the bone and periodontal lesion are of utmost importance. A prior collaborative effort between the previously mentioned departments has already resulted in the development of an AI algorithm capable of differentiating between bone and nerve tissue in the mandibular bone. The subsequent objective is to automatically detect periodontal lesions within the bone. [8]&lt;/p&gt;
&lt;p&gt;The prospective student will explore existing deep-learning-based segmentation methods for training with limited data, to segment periodontal lesions in MR sequences.&lt;/p&gt;
&lt;p&gt;Requirements:&lt;/p&gt;
&lt;p&gt;• Prior experience and good understanding in machine learning and statistics.
• Very good programming skills in Python (and PyTorch).
• Interest in medical imaging.&lt;/p&gt;
&lt;p&gt;References
[1]  Cheplygina, V. ”Cats or CAT scans: Transfer learning from natural or medical image source data sets?.” Current Opinion in Biomedical Engineering 9: 21-27, 2019.
[2]  Chen, L., et al. Self-supervised learning for medical image analysis using image context restoration. Medical image analysis, 58, 101539, 2019.
[3]  Taleb, A., et al. ”Multimodal self-supervised learning for medical image analysis.” International Conference on Information Processing in Medical Imaging. Springer, Cham, 2021.
[4]  Li, X., et al. ”A concise review of recent few-shot meta-learning methods.” Neuro- computing 456: 463-468, 2021.
[5]  Yang, B., et al. ”Prototype mixture models for few-shot semantic segmentation.” European Conference on Computer Vision. Springer, Cham, 2020.
[6]  Tian, P., et al. ”Differentiable meta-learning model for few-shot semantic segmen- tation.” Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 07. 2020.
[7]  Probst, M., et al. ”Magnetic resonance imaging as a diagnostic tool for periodontal disease: A prospective study with correlation to standard clinical findings - Is there added value?” Journal of Clinical Periodontology, 2021.
[8] Xingyu, Z., (2024) “Multi-object and Multi-modal Image Segmentation in Dental MRI”. School of Computation, Information and Technology, Technical University of Munich, Munich.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning-Based Segmentation of Perfusion MRI</title>
      <link>https://compai-lab.io/vacancies/msc_segmentation_hannah/</link>
      <pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_segmentation_hannah/</guid>
      <description>&lt;p&gt;Jointly supervised with Gabriel Hoffmann and Christine Preibisch (TUM Universitätsklinikum).&lt;/p&gt;
&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;This project aims to develop and validate deep learning models for the automatic segmentation of perfusion territories in super-selective arterial spin labeling (ss-ASL) data and for the segmentation of individual watershed areas from contrast-agent-based time-to-peak (TTP) maps. The project will leverage the nnUNET framework, which is known for its robustness and flexibility in medical image segmentation tasks. Currently, expert segmentations are highly time-consuming and labor-intensive. Automating these segmentations with a reliable deep learning model will significantly enhance research efficiency and accuracy.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contrastive Learning Strategies for Medical Imaging</title>
      <link>https://compai-lab.io/vacancies/msc_contrastive_learning_maxime/</link>
      <pubDate>Fri, 31 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_contrastive_learning_maxime/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Self-Supervised Learning (SSL) overcomes the limitations of most learning methods, which require high-quality labelled data. Contrastive learning is a popular technique of SSL, where a model learns to distinguish between similar and dissimilar examples by bringing similar data points closer and dissimilar ones farther apart in the feature space. A key element of contrastive learning is defining the positive and negative pairs, as the model learns by comparing these pairs to adjust its representation. Proper pair selection is crucial for the effectiveness of the learned embeddings.&lt;/p&gt;
&lt;p&gt;This project aims to compare different strategies for defining pairs in contrastive learning for medical applications. The first part of the project will involve identifying and comparing state-of-the-art strategies on medical tasks. The second part will focus on evaluating and proposing new strategies.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Diffusion-Based Correspondences between Multimodal Medical Images</title>
      <link>https://compai-lab.io/vacancies/msc_diffusion_features_anna/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_diffusion_features_anna/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Lesion tracking and image registration (finding the deformation between two images) are fundamental tasks in clinical practice for the diagnosis and monitoring of diseases. For this, establishing correct point correspondences between multiple images is essential.
Recent research in computer vision explores the use of diffusion model features for various image-based downstream tasks, including object detection, tracking, image editing, and classification, as well as the fusion of high-level semantic and low-level geometric features.
This thesis aims to adapt diffusion model-based features to medical images. In particular, the student will (i) perform literature research on the topic, (ii) explore SOTA correspondence matching techniques in the context of medical images, and (iii) develop new techniques for specific tasks on multimodal images, e.g., MR and CT. The project can be adapted to the student’s interests.&lt;/p&gt;
&lt;p&gt;The start date ideally is February/March 2025. The thesis is offered by the Chair for Computational Imaging and AI in Medicine (Prof. Dr. Julia Schnabel) and supervised by Anna Reithmeir and Dr. Daniel Lang. If interested, please send your transcripts and a short motivation to &lt;a href=&#34;mailto:anna.reithmeir@tum.de&#34;&gt;anna.reithmeir@tum.de&lt;/a&gt; and
&lt;a href=&#34;mailto:lang@helmholtz-munich.de&#34;&gt;lang@helmholtz-munich.de&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Integrating Location Context in Patch-based 3D Medical Image Segmentation</title>
      <link>https://compai-lab.io/vacancies/msc_stefan/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_stefan/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Deep learning-based semantic segmentation is highly effective for detecting and segmenting tumors, anomalies, and organs-at-risk in medical imaging.
Unlike general computer vision tasks, medical imaging involves unique challenges, such as large 3D volumes from CT and MRI scans that require substantial computational resources.
To manage memory constraints, state-of-the-art models like nnUNet and SwinUNETR use patch-based methods, dividing 3D scans into smaller subvolumes.
The choice of patch size is crucial—large enough to retain meaningful anatomical context but small enough to fit within hardware limitations.
Networks must also infer the relative position of patches within the body to maintain spatial coherence in segmentation tasks.
Additional location information can be incorporated using image coordinates, physical scanner coordinates, or body-part regression tools.
This project aims to evaluate different methods for integrating location information into CNNs and Transformers for 3D medical image segmentation.
Techniques under consideration include coordinate images as additional channels, CoordConv layers, attention mechanisms, and positional embeddings.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Temporal Landmark Tracking on Medical Imaging</title>
      <link>https://compai-lab.io/vacancies/msc_tracking_lang_reithmeir/</link>
      <pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_tracking_lang_reithmeir/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Even though various learning-based computer vision methods have been developed for pixel tracking, motion estimation in video data depicts a challenging task. Part of the problem arises from the 3D-to-2D projection process that can lead to out-of-plane motion, which impedes long-range pixel trajectory estimation. In the medical domain, video data, i.e. fast magnetic resonance imaging (MRI) sequences, can be used for guidance during treatment. Specifically, in radiation therapy, contouring algorithms are used for tracking of the target volume supposed to receive the main radiation dose during treatment. Delineation can, for example, be performed with a U-Net architecture. However, such an approach only allows for identification of larger structures, while irregular movement can be subtle and localized. Landmark detection models are able to identify such localized regions between different representations of the same object. Furthermore, they are faster than semantic segmentation models, and therefore, allow for computer aided intervention during treatment. In this thesis, different state-of-the-art landmark and pixel tracking algorithms will be tested and further enhanced to identify movement on temporal imaging data of the lungs, i.e. 4D CT. Furthermore, ability of such landmarks to identify movement differing from a normal state, i.e. allowing for identification of anomalies, will be studied.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Latent Diffusion Models For Cardiac Attribute Regularization</title>
      <link>https://compai-lab.io/vacancies/msc_latent_diffusion_maxime/</link>
      <pubDate>Sun, 30 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_latent_diffusion_maxime/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Diffusion models have recently caught the attention of the medical imaging community by producing realistic synthetic images. Recent efforts have focused on improving model controllability of the generation process by allowing selective modifications of data attributes, such as altering the gender of a person in an image. Latent Diffusion Models (LDMs) can be used to generate realistic data of brain MRI controlled by attributes such as age, sex, and brain structure volumes.&lt;/p&gt;
&lt;p&gt;This project aims to use latent diffusion models to generate realistic cardiac MRI and control the generation process by given attributes such as age, cardiac volumes, etc.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Riemannian Manifolds for Medical Image Classification</title>
      <link>https://compai-lab.io/vacancies/msc_manifolds_reithmeir/</link>
      <pubDate>Sat, 08 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_manifolds_reithmeir/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;This Master’s project aims to explore the use of covariance descriptors for disease classification with medical&lt;/p&gt;
&lt;p&gt;images. First, the MedMNIST toy dataset will be explored. Then, the student will work with an open-source&lt;/p&gt;
&lt;p&gt;medical dataset, e.g. of 2D chest x-ray or 3D cardiac MR images&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Segmentation of sparse annotated data - application to cardiac imaging</title>
      <link>https://compai-lab.io/vacancies/msc_segmentation_maxime/</link>
      <pubDate>Fri, 30 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_segmentation_maxime/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;In cardiac MR, segmenting the left ventricle, the right ventricle and the myocardium is a common task in clinical routine. Several state-of-the-art deep learning algorithms are able to achieve reliable and great performances for this task. Nevertheless, it is often performed in a supervised way, i.e. annotated data are needed. Because these annotations are time-consuming for the clinician to make, recent works focus on being able to limit the needs of annotation and still provide robust and reliable segmentation. Different strategies exist to overcome this limitation, such as transfer learning or self-supervised learning, which are learning prior knowledge on a similar annotated dataset or without any annotation.&lt;/p&gt;
&lt;p&gt;The objective of this project is to be able to provide robust and reliable segmentation of a sparse annotated cardiac MR dataset. The prospective student will develop a segmentation network based on recent strategies for sparsed annotated data and compare them to state-of-the-art deep-learning segmentation methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning for Smooth Surface and Normal Fields Reconstruction</title>
      <link>https://compai-lab.io/vacancies/msc_surface_zimmer/</link>
      <pubDate>Mon, 21 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_surface_zimmer/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;In recent years, unsupervised and semi-supervised learning from populations of surfaces and curves has received a lot of attention. Such data representations are analyzed according to their shapes which open a broad range of applications in machine learning, robotics, statistics and engineering. In particular, studying the shape of surfaces have become an important tool in biology and medical imaging. The extraction of appropriate data representations, such as triangulated surfaces, is crucial for the subsequent analysis. These surfaces are for example obtained from binary segmentations or 3D point clouds. Using standard methods, such surfaces are often not very accurate and require several post-processing steps, such as smoothing and simplifications.
Deep learning based methods are of great interest in various fields such as medical imaging, com- puter vision, applied mathematics and are successfully used in the field of image segmentation. Gener- ally, a specific formulation requires a particular attention to representations, loss functions, probability models, optimization techniques, etc. This choice is very crucial due to the underlying geometry on the space of representations and constraints. we aim to develop a new set of automatic methods that can compute a triangulation and a normal field from a 3D dataset (binary image and/or 3D point cloud).
The goal of this project is to understand the-state-of-the-art methods (e.g., [?]) and to propose solutions in the context of constructing a mesh from 3D images/point sets. We are interested in learn- ing from a dataset of smooth surfaces and their corresponding 3D datasets to make the triangulation or resampling accurate. The application will be the extraction of a smooth surfaces from μ-CT and CT data of the cochlea and inner ear, whose shapes can then be analyzed subsequently for population studies.
To summarize, the key steps are : (i) Literature review and getting familiar with some state-of- the-art methods in the medical context; (ii) Implementing and testing the code before validation on real data; (iii) Optimizing the code and comparing with baseline methods. If successful, the method would be applied to analyze and classify surfaces.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
