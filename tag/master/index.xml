<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>master | Computational Imaging and AI in Medicine</title>
    <link>https://compai-lab.io/tag/master/</link>
      <atom:link href="https://compai-lab.io/tag/master/index.xml" rel="self" type="application/rss+xml" />
    <description>master</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 07 Nov 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://compai-lab.io/media/icon_hu790efcb2e4090d1e7a0ffec0a0776e8f_331139_512x512_fill_lanczos_center_3.png</url>
      <title>master</title>
      <link>https://compai-lab.io/tag/master/</link>
    </image>
    
    <item>
      <title>Multiparametric (TI-TE) MRI sequence adaptation and implicit neural representation (INR)-based reconstruction</title>
      <link>https://compai-lab.io/vacancies/msc_niessen_reconstruction_26/</link>
      <pubDate>Fri, 07 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_niessen_reconstruction_26/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Multiparametric MRI sequences allow for the acquisition of images with varying tissue contrast within a single scan. The resulting multiparametric images can be used to extract quantitative information on tissue microstructure. To make such multiparametric sequences feasible for clinical routine, the usually very long scan times need to be shortened e.g. through undersampling in k-space. However, this comes with challenges for the reconstruction. In general, advanced reconstruction techniques such as compressed sensing or deep learning based approaches (1) can enable the acquisition of high-quality images despite the acceleration. For multiparametric MRI sequences very high accelerations can be achieved by leveraging redundant anatomical information e.g. through joint reconstruction with an implicit neural representation (INR) network (2).&lt;/p&gt;
&lt;p&gt;This project aims to extend an MPnRAGE (3) (multiple inversion times, TI) acquisition and reconstruction framework by adding an echo time (TE) dimension. The first part of the project will involve modifying the existing MPnRAGE sequence, including iterative improvements on the scanner. The second part of the project will focus on adapting the INR-based reconstruction for the multiparametric (TI-TE) data.&lt;/p&gt;
&lt;p&gt;The student will benefit from:
• Guidance from both MRI and AI experts in a collaborative, interdisciplinary research
setting.
• Hands on experience with the MRI scanner and coding.
• Opportunity to contribute to ongoing research and potential publication in medical
imaging journals or conferences.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Med-VLM - Prompt Adaptation of Vision-Language Models to Medical Domains</title>
      <link>https://compai-lab.io/vacancies/msc_med-vlm_sameer/</link>
      <pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_med-vlm_sameer/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Medical imaging faces persistent domain shifts across scanners, protocols, pathologies, and populations. Recent vision-language models, such as CLIP (Contrastive Language-Image Pre-training), learns joint representations from image-text pairs, enabling zero-shot transfer to new visual concepts through natural language descriptions. Although the recent works demonstrate that CLIP based models offer strong zero-shot transfer, their performance degrades on unseen medical data.&lt;/p&gt;
&lt;p&gt;Recent adaptation techniques aim to mitigate this by proposing prompt-based, parameter-efficient, and feature-level strategies. Complementing this, text-only prompt learning optimizes prompts in the text space using LLM-derived biomedical descriptions or ontology-based prototypes, improving transfer to unseen data. This Master&amp;rsquo;s thesis proposes adapting CLIP-based models to unseen medical data through techniques including prompt learning and CLIP&amp;rsquo;s consistent contrastive alignment, emphasizing practical clinical feasibility.&lt;/p&gt;
&lt;p&gt;This Master thesis aims to analyze and propose: (i) an adaptation framework that leverages medical concepts into prompts to improve robustness on unseen data, (ii) prompt-based adaptation procedures for non-independent and identically distributed (non-i.i.d) shifts through lightweight mechanisms, (iii) a comprehensive evaluation on multi-source medical benchmarks. Expected outcomes include, but are not limited to: a vision and language-guided framework for medical imaging that improves generalization across multiple scanners and diverse population data, a lightweight test-time adaptation method with biomedical prompts, and analysis on medical benchmarks with ablations under realistic scenarios. This Master&amp;rsquo;s thesis aspires to publish results in a relevant academic venue.&lt;/p&gt;
&lt;p&gt;The start date ideally is Sept/Oct 2025. The thesis is offered by the Chair for Computational Imaging and AI in Medicine (Prof. Dr. Julia Schnabel) and supervised by Sameer Ambekar and Dr. Daniel Lang. If interested, please email your transcripts and a short motivation to &lt;a href=&#34;mailto:sameer.ambekar@tum.de&#34;&gt;sameer.ambekar@tum.de&lt;/a&gt; and
&lt;a href=&#34;mailto:lang@helmholtz-munich.de&#34;&gt;lang@helmholtz-munich.de&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning from Many - Domain Generalization for Medical Imaging</title>
      <link>https://compai-lab.io/vacancies/msc_ambekar_domain_shift_25/</link>
      <pubDate>Wed, 04 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_ambekar_domain_shift_25/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Deep learning achieves good performance when training and test data share similar distribution characteristics. However, for real-world scenarios—including medical imaging and natural scenes—significant domain shifts caused by diverse data characteristics and scanner settings often prevent models from generalizing to unseen domains. To address this at the model level, domain adaptation and domain generalization have emerged as potential solutions. Domain adaptation relies on access to target data to learn target representations, while domain generalization aims to learn invariant representations and obtain robust models using only source domains. Recently, a new paradigm called test-time adaptation further optimizes the model during online inference on the target domain to boost performance.&lt;/p&gt;
&lt;p&gt;Despite these advancements, existing adaptation methods struggle with unique challenges in the target domain. These include class imbalance, category shifts within domains, reliance on unsupervised surrogate objectives, and non-i.i.d. assumptions that lead to error accumulation. Moreover, the scarcity of large annotated datasets limits the ability of models to learn meaningful representations for transfer. Recent studies also show that existing methods do not consistently improve performance in multi-source, real-world scenarios such as medical imaging.&lt;/p&gt;
&lt;p&gt;This master’s thesis proposes new domain generalization and adaptation techniques to address these challenges. First, it will train models on multi-source data drawn from diverse distributions—different scanners, pathologies, and demographics. Next, it will explore existing domain generalization algorithms, analyzing the role of entropy minimization for optimizing model performance and the impact of feature alignment. Finally, it seeks to introduce novel contributions grounded in fundamental deep learning principles, with the goal of enhancing the adaptability and robustness of models across varied environments. The research outcomes are intended for publication in a relevant academic venue.&lt;/p&gt;
&lt;p&gt;The start date ideally is June 2025. The thesis is offered by the Chair for Computational Imaging and AI in Medicine (Prof. Dr. Julia Schnabel) and supervised by Sameer Ambekar and Dr. Daniel Lang. If interested, please send your transcripts and a short motivation to &lt;a href=&#34;mailto:sameer.ambekar@tum.de&#34;&gt;sameer.ambekar@tum.de&lt;/a&gt; and
&lt;a href=&#34;mailto:lang@helmholtz-munich.de&#34;&gt;lang@helmholtz-munich.de&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-object and multi-modal image segmentation in dental MR using limited data</title>
      <link>https://compai-lab.io/vacancies/msc_lina_dental/</link>
      <pubDate>Wed, 04 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_lina_dental/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Deep learning methods have revolutionized the field of medical imaging, in particular image segmentation. Supervised methods, often based on the popular U-Net architecture, show state-of-the-art results in many medical applications. But a large annotated database for training is not always available. The objective of this project is to explore and develop methods for learning segmentations using limited data, e.g., using transfer [1], self-supervised [2,3] or meta learning [4–6]. This project is a collaboration between the Department of Diagnostic and Interventional Neuroradiology (TUM), the Department of Periodontology (LMU) and the Chair of the Artificial Intelligence in Medicine (TUM).&lt;/p&gt;
&lt;p&gt;The clinical application is the identification of periodontal lesions in magnetic resonance (MR) and computed tomography (CT) images. The study aims at detecting intraosseous pathologies automatically. Periodontitis (chronic or acute alterations of the periodontium) is among the globally widest spread diseases, and interacts with cardiovascular and metabolic disorders. The diagnosis and monitoring of periodontitis is mainly based on imaging modalities exhibiting ionizing radiation: X-ray (panoramic radiography) and cone-beam CT. Recent studies report the successful use of MR imaging in the application of periodontitis diagnosis [7]. Two MRI sequences were developed: a T1-weighted sequence to visualise osseous tissue, and a T2-weighted sequence to visualise the periodontal lesion. To enable automatic diagnosis and monitoring of the disease, accurate segmentations of the bone and periodontal lesion are of utmost importance. A prior collaborative effort between the previously mentioned departments has already resulted in the development of an AI algorithm capable of differentiating between bone and nerve tissue in the mandibular bone. The subsequent objective is to automatically detect periodontal lesions within the bone. [8]&lt;/p&gt;
&lt;p&gt;The prospective student will explore existing deep-learning-based segmentation methods for training with limited data, to segment periodontal lesions in MR sequences.&lt;/p&gt;
&lt;p&gt;Requirements:&lt;/p&gt;
&lt;p&gt;• Prior experience and good understanding in machine learning and statistics.
• Very good programming skills in Python (and PyTorch).
• Interest in medical imaging.&lt;/p&gt;
&lt;p&gt;References
[1]  Cheplygina, V. ”Cats or CAT scans: Transfer learning from natural or medical image source data sets?.” Current Opinion in Biomedical Engineering 9: 21-27, 2019.
[2]  Chen, L., et al. Self-supervised learning for medical image analysis using image context restoration. Medical image analysis, 58, 101539, 2019.
[3]  Taleb, A., et al. ”Multimodal self-supervised learning for medical image analysis.” International Conference on Information Processing in Medical Imaging. Springer, Cham, 2021.
[4]  Li, X., et al. ”A concise review of recent few-shot meta-learning methods.” Neuro- computing 456: 463-468, 2021.
[5]  Yang, B., et al. ”Prototype mixture models for few-shot semantic segmentation.” European Conference on Computer Vision. Springer, Cham, 2020.
[6]  Tian, P., et al. ”Differentiable meta-learning model for few-shot semantic segmen- tation.” Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 07. 2020.
[7]  Probst, M., et al. ”Magnetic resonance imaging as a diagnostic tool for periodontal disease: A prospective study with correlation to standard clinical findings - Is there added value?” Journal of Clinical Periodontology, 2021.
[8] Xingyu, Z., (2024) “Multi-object and Multi-modal Image Segmentation in Dental MRI”. School of Computation, Information and Technology, Technical University of Munich, Munich.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Contrastive Learning Strategies for Medical Imaging</title>
      <link>https://compai-lab.io/vacancies/msc_contrastive_learning_maxime/</link>
      <pubDate>Fri, 31 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://compai-lab.io/vacancies/msc_contrastive_learning_maxime/</guid>
      <description>&lt;p&gt;Abstract:&lt;/p&gt;
&lt;p&gt;Self-Supervised Learning (SSL) overcomes the limitations of most learning methods, which require high-quality labelled data. Contrastive learning is a popular technique of SSL, where a model learns to distinguish between similar and dissimilar examples by bringing similar data points closer and dissimilar ones farther apart in the feature space. A key element of contrastive learning is defining the positive and negative pairs, as the model learns by comparing these pairs to adjust its representation. Proper pair selection is crucial for the effectiveness of the learned embeddings.&lt;/p&gt;
&lt;p&gt;This project aims to compare different strategies for defining pairs in contrastive learning for medical applications. The first part of the project will involve identifying and comparing state-of-the-art strategies on medical tasks. The second part will focus on evaluating and proposing new strategies.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
